# ğŸ¤– Automated Monthly Data Collection System

**Date:** October 2, 2025  
**Goal:** Ensure every client (current & future) has monthly data saved automatically when each month ends  
**Status:** ğŸ”§ BUILDING

---

## ğŸ¯ System Requirements

### **What We Need:**

1. âœ… **Automatic Monthly Save:** When month ends â†’ Save all client data
2. âœ… **Rich Campaign Details:** Save full campaign breakdown (not just totals)
3. âœ… **All Clients:** Process ALL active clients (current and future)
4. âœ… **Platform Separation:** Meta and Google Ads tracked separately
5. âœ… **No Manual Intervention:** Fully automated via cron job
6. âœ… **Quality Validation:** Skip if rich data already exists
7. âœ… **Error Recovery:** Continue if one client fails

---

## ğŸ“Š Current System Analysis

### **What Already Exists:**

#### **1. Monthly Aggregation Endpoint** âœ…
- **File:** `src/app/api/automated/monthly-aggregation/route.ts`
- **Purpose:** Aggregates data for previous month
- **Status:** EXISTS but needs enhancement

#### **2. Backfill Endpoint** âœ…
- **File:** `src/app/api/backfill-all-client-data/route.ts`
- **Purpose:** Backfills historical data
- **Status:** FIXED (quality validation added)

#### **3. Database Tables** âœ…
- `campaign_summaries` - Stores monthly summaries with campaigns
- `clients` - All client records
- Platform column enforces Meta/Google separation

---

## ğŸ”§ System Architecture

### **Flow Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRIGGER: 1st of every month at 2:00 AM                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Get All Active Clients                             â”‚
â”‚  - Query: SELECT * FROM clients WHERE api_status = 'active'â”‚
â”‚  - Includes: Meta token, Google token, account IDs         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Calculate Previous Month Dates                     â”‚
â”‚  - Start: First day of previous month                      â”‚
â”‚  - End: Last day of previous month                         â”‚
â”‚  - Example: On Oct 1, process Sept 1-30                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: For Each Client - Check Existing Data              â”‚
â”‚  - Query campaign_summaries for previous month             â”‚
â”‚  - Check if RICH data exists (has campaigns)               â”‚
â”‚  - If rich data exists â†’ SKIP                              â”‚
â”‚  - If no data or poor quality â†’ FETCH                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Fetch Data from Meta/Google APIs                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Meta Ads API:                                      â”‚    â”‚
â”‚  â”‚  - Get campaigns with spend/impressions/clicks     â”‚    â”‚
â”‚  â”‚  - Get conversion metrics (reservations, etc.)     â”‚    â”‚
â”‚  â”‚  - Get demographics, placements, ad relevance      â”‚    â”‚
â”‚  â”‚  - Save to campaign_summaries with platform='meta' â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Google Ads API:                                    â”‚    â”‚
â”‚  â”‚  - Get campaigns with spend/impressions/clicks     â”‚    â”‚
â”‚  â”‚  - Get conversion metrics                          â”‚    â”‚
â”‚  â”‚  - Save to campaign_summaries with platform='google'â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Store in Database                                  â”‚
â”‚  - UPSERT to campaign_summaries table                      â”‚
â”‚  - Includes: campaigns array, conversion metrics, totals   â”‚
â”‚  - Platform tag: 'meta' or 'google'                        â”‚
â”‚  - Conflict resolution: Skip if rich data exists           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Send Summary Email (Optional)                      â”‚
â”‚  - Success: "September data saved for 15 clients"          â”‚
â”‚  - Failures: "3 clients failed (list reasons)"             â”‚
â”‚  - Send to: admin@example.com                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Implementation Plan

### **Task 1: Fix Existing Monthly Aggregation Endpoint**

**Current issues:**
- Might not check data quality
- Might not handle all clients
- Might not have platform separation

**What to fix:**
1. Add quality check (skip if has campaigns)
2. Process all active clients automatically
3. Enforce platform separation
4. Add error handling per client

---

### **Task 2: Create Cron Job Configuration**

**Options:**

#### **Option A: Vercel Cron (Recommended for Production)**
```json
// vercel.json
{
  "crons": [
    {
      "path": "/api/automated/monthly-aggregation",
      "schedule": "0 2 1 * *"
    }
  ]
}
```
**Schedule:** 2:00 AM on the 1st of every month

#### **Option B: Supabase Cron (Alternative)**
```sql
-- Run via Supabase Edge Functions
SELECT cron.schedule(
  'monthly-data-collection',
  '0 2 1 * *',
  $$
  SELECT net.http_post(
    url:='https://yourapp.com/api/automated/monthly-aggregation',
    headers:='{"Content-Type": "application/json"}'::jsonb
  );
  $$
);
```

#### **Option C: GitHub Actions (For Testing)**
```yaml
# .github/workflows/monthly-aggregation.yml
on:
  schedule:
    - cron: '0 2 1 * *'  # 2 AM on 1st of month
  workflow_dispatch:  # Manual trigger for testing
```

---

### **Task 3: Add Platform Field Migration**

**Fix existing NULL platforms:**
```sql
-- Migration to backfill NULL platforms
UPDATE campaign_summaries 
SET platform = 'meta' 
WHERE platform IS NULL;
```

---

### **Task 4: Add New Client Onboarding Check**

**When new client is added:**
```typescript
// After creating new client
// Optionally backfill last 3 months of data
await fetch('/api/backfill-all-client-data', {
  method: 'POST',
  body: JSON.stringify({
    clientIds: [newClientId],
    monthsToBackfill: 3,
    platform: 'all',
    forceRefresh: false
  })
});
```

---

## ğŸ“‹ Complete Implementation Checklist

### **Phase 1: Fix Current Data (Immediate)**
- [ ] Run `FIX_NULL_PLATFORMS.sql` to fix September
- [ ] Run `FIX_AUGUST_DATA_NOW.sh` to backfill August
- [ ] Verify all historical months have rich data

### **Phase 2: Enhance Monthly Aggregation Endpoint**
- [ ] Add quality check (skip if has campaigns)
- [ ] Add per-client error handling
- [ ] Add platform separation validation
- [ ] Add detailed logging
- [ ] Add email notification on completion

### **Phase 3: Set Up Automation**
- [ ] Choose cron solution (Vercel/Supabase/GitHub)
- [ ] Configure cron job for 1st of month
- [ ] Test manual trigger
- [ ] Monitor first automated run

### **Phase 4: New Client Onboarding**
- [ ] Add backfill to client creation flow
- [ ] Document process for adding new clients
- [ ] Test with dummy client

### **Phase 5: Monitoring & Alerts**
- [ ] Add health check endpoint
- [ ] Set up error monitoring (Sentry?)
- [ ] Create admin dashboard for data status
- [ ] Weekly email report on data completeness

---

## ğŸš€ Quick Start Commands

### **1. Fix Current Data Now**
```bash
# Fix NULL platforms
# Run in Supabase SQL Editor:
UPDATE campaign_summaries SET platform = 'meta' WHERE platform IS NULL;

# Backfill poor quality months
./FIX_AUGUST_DATA_NOW.sh
```

### **2. Test Monthly Aggregation**
```bash
# Manual trigger to test the endpoint
curl -X POST http://localhost:3000/api/automated/monthly-aggregation \
  -H "Content-Type: application/json" \
  -d '{
    "targetMonth": "2025-09",
    "dryRun": true
  }'
```

### **3. Enable Cron Job**
```bash
# Deploy with Vercel cron
vercel --prod
# Vercel will automatically detect vercel.json cron config
```

---

## ğŸ“Š Data Quality Guarantees

After implementation, every month will have:

âœ… **All Active Clients** - No one left behind  
âœ… **Rich Campaign Data** - Full campaign breakdown  
âœ… **Conversion Metrics** - Reservations, ROAS, funnel steps  
âœ… **Platform Separated** - Meta and Google distinct  
âœ… **No Duplicates** - UNIQUE constraint enforced  
âœ… **Quality Validated** - Only saves if complete  
âœ… **Error Recovery** - One failure doesn't stop others  

---

## ğŸ¯ Expected Outcome

**What happens on October 1st at 2:00 AM:**

```
ğŸ¤– Monthly Aggregation Started
  â”œâ”€ Found 15 active clients
  â”œâ”€ Target month: September 2025
  â”‚
  â”œâ”€ Client 1 (Belmonte Hotel):
  â”‚   â”œâ”€ Check: September data exists? Yes (22 campaigns)
  â”‚   â””â”€ Action: SKIP (rich data already exists) âœ…
  â”‚
  â”œâ”€ Client 2 (Hotel XYZ):
  â”‚   â”œâ”€ Check: September data exists? No
  â”‚   â”œâ”€ Fetch: Meta API â†’ 15 campaigns, 8,432 PLN
  â”‚   â”œâ”€ Fetch: Google API â†’ 8 campaigns, 3,211 PLN
  â”‚   â””â”€ Action: SAVED both platforms âœ…
  â”‚
  â”œâ”€ Client 3 (Restaurant ABC):
  â”‚   â”œâ”€ Check: September data exists? Yes (0 campaigns)
  â”‚   â”œâ”€ Quality: Poor (no campaigns)
  â”‚   â”œâ”€ Fetch: Meta API â†’ 12 campaigns, 5,123 PLN
  â”‚   â””â”€ Action: UPDATED with rich data âœ…
  â”‚
  â””â”€ Summary:
      â”œâ”€ Total: 15 clients
      â”œâ”€ Skipped: 8 (already have rich data)
      â”œâ”€ Updated: 6 (poor quality replaced)
      â”œâ”€ Failed: 1 (API error, will retry tomorrow)
      â””â”€ Duration: 4 minutes

ğŸ“§ Email sent to admin with summary
```

---

## ğŸ” Monitoring Dashboard (Future Enhancement)

Create admin page: `/admin/data-health`

```
Data Health Dashboard
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Last Automated Run: Oct 1, 2025 2:04 AM âœ…

September 2025 Status:
  Clients with rich data: 14 / 15 âœ…
  Clients missing data: 1 âš ï¸
    - Hotel XYZ (API error: token expired)

August 2025 Status:
  Clients with rich data: 15 / 15 âœ…

July 2025 Status:
  Clients with rich data: 15 / 15 âœ…

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Actions Available:
  [Retry Failed Clients]
  [Manual Trigger for September]
  [View Detailed Logs]
```

---

## ğŸ“ Next Steps

**Which approach do you want?**

### **Option 1: Quick Fix (Today)**
- âœ… Fix NULL platforms
- âœ… Enhance existing monthly aggregation
- âœ… Set up Vercel cron
- â±ï¸ Time: 1-2 hours

### **Option 2: Complete System (This Week)**
- âœ… Everything from Option 1
- âœ… Admin dashboard
- âœ… Email notifications
- âœ… New client onboarding flow
- â±ï¸ Time: 1-2 days

### **Option 3: Enterprise Grade (This Month)**
- âœ… Everything from Option 2
- âœ… Error monitoring (Sentry)
- âœ… Data quality alerts
- âœ… Automatic retry logic
- âœ… Historical data validation
- â±ï¸ Time: 1 week

---

**Tell me which option you prefer, and I'll start implementing!** ğŸš€

